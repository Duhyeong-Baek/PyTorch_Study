{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYZ-hhGQ78BJ",
        "outputId": "bc2ce81b-f2be-4581-d21b-39c46db2ece2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.4480]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1534], requires_grad=True)\n",
            "tensor([0.6013], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "x=torch.tensor([1.])\n",
        "model = nn.Linear(1, 1) # 입력 노드 하나, 출력 노드 하나인 layer 만듦\n",
        "\n",
        "print(model.weight) # 만들면서 초기화\n",
        "print(model.bias)\n",
        "\n",
        "# 인공신경망은 함수다. y = wx + b\n",
        "y = model(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x @ model.weight + model.bias\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrLYRDtA8Xji",
        "outputId": "50cbe735-3de1-4bbf-a565-92be538b6568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6013], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc1 = nn.Linear(1,3)\n",
        "fc2 = nn.Linear(3,1) # 입력 노드 3개가 전부 연결되어 있는, Fully Connected Layer\n",
        "\n",
        "print(fc1.weight)\n",
        "print(fc1.bias) # 출력노드가 얼마나 민감/둔감하게 반응할지 조정해주는 역할인 bias\n",
        "\n",
        "# 출력 노드가 3개니까, bias도 3개\n",
        "\n",
        "print(fc2.weight)\n",
        "print(fc2.bias) # 출력 노드가 1개니까, bias도 1\n",
        "\n",
        "# (1->3) -> (3->1) 과정\n",
        "x=torch.tensor([1.])\n",
        "x = fc1(x)\n",
        "print(x)\n",
        "\n",
        "x = fc2(x)\n",
        "print(x)\n",
        "\n",
        "# 수식적 표현\n",
        "x = torch.tensor([1.])\n",
        "# y = (x@fc1.weight+fc1.bias)@fc2.weight + fc2.bias # Transpose 안하면 사이즈 오류\n",
        "y = (x@fc1.weight.T+fc1.bias)@fc2.weight.T + fc2.bias\n",
        "\n",
        "print(y)\n",
        "\n",
        "# nn.Linear는 개x채x행x렬에서 \"채널()\" 형태로 (ID data) 들어오길 기대하는 녀석이다\n",
        "# 즉, 노드 하나가 한 채널 의미\n",
        "# 따라서, 데이터 여러 개를 통과시키고 싶다면, (개x채) 형태로 줘야함\n",
        "# why T? weight도 개x채 형태로 만들기 위함!\n",
        "# 일단, weight shape 개x채에서 채는 무조건 앞에 거 채널 수와 맞추셈! (원칙)\n",
        "# 예를 들면, nn.Linear(2,3) 이면 인풋의 채널 개수는 2\n",
        "# 따라서 ?x2인데, \"두 채널 값을 가지고 3개의 노드를 만드는 거\"라서 3x2가 된다\n",
        "\n",
        "# 원칙을 적용해야하니까,\n",
        "\n",
        "# x와 같이 1d 데이터는 \"채\" 형태. 만약 (3,4) 형태로 들어오면, 4개짜리 채널이 3개 있다\n",
        "# 행x렬은 \"이미지\"에서 필요.\n",
        "\n",
        "# (2,3) Layer일 때\n",
        "# [x1 x2] [w1 w3 w5] + [b1 b2 b3]\n",
        "#         [w2 w4 w6]\n",
        "\n",
        "# 여기서 활성화 함수 먹이고, 다시 행렬곱, bias 더하는 것 반복\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCmjGFq59aE_",
        "outputId": "87a1c27b-89ac-4d05-9a03-27d588a7f5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.8857],\n",
            "        [ 0.5589],\n",
            "        [ 0.2470]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.1661, -0.0543, -0.8279], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.3666,  0.1444,  0.3386]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.3044], requires_grad=True)\n",
            "tensor([-0.7196,  0.5046, -0.5809], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1644], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1644], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc1 = nn.Linear(1,3)\n",
        "fc2 = nn.Linear(3,1)\n",
        "\n",
        "model = nn.Sequential(fc1, fc2) # (1,3)과 (3,1)을 갖다 붙이는 함수\n",
        "x= torch.tensor([1.])\n",
        "model(x) # (1->3->1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRZ2SFcvB-pg",
        "outputId": "359530e4-6915-49bc-cfe5-b798c92fff52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1721], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(2,5), # 채X\n",
        "              nn.Linear(5,10),\n",
        "              nn.Linear(10,3))\n",
        "\n",
        "x = torch.randn(2)\n",
        "print(model(x))\n",
        "\n",
        "x = torch.randn(5, 2) # 두 채널 값(키, 몸무게)를 가지는 데이터(사람) 5개\n",
        "# 신경망 들어갈 때는 노드 2개만 필요. 데이터 5개는 신경망을 5번 통과하는 것!\n",
        "\n",
        "print(model(x))\n",
        "\n",
        "x = torch.randn(2,3,1,4,5,2) # Linear는 무조건 개x채. 마지막만 채이고, 앞에 있는 것들은 모두 개\n",
        "print(model(x).shape) # (2 -> 3)으로 나오는 신경망을 2x3x1x4x5 개를 각각 통과시켜 쌓은 결과물\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R80Wma_UEoAY",
        "outputId": "d58198ba-325d-4c58-988f-8540b8a585dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2944, 0.2863, 0.0381], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.5085,  0.1696,  0.0518],\n",
            "        [ 0.2627,  0.1462, -0.0320],\n",
            "        [ 0.3750,  0.2396,  0.0421],\n",
            "        [-0.0354,  0.0642, -0.1570],\n",
            "        [ 0.3662,  0.1866,  0.0165]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([2, 3, 1, 4, 5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(2, 5)\n",
        "    self.fc2 = nn.Linear(5, 10)\n",
        "    self.fc3 = nn.Linear(10, 3)\n",
        "    self.sig1 = nn.Sigmoid()\n",
        "    self.sig2 = nn.Sigmoid()\n",
        "    self.sig3 = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.sig1(x) # 여기까지 한 층\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    x = self.sig2(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "    x = self.sig3(x)\n",
        "    return x\n",
        "\n",
        "model = MyModel()\n",
        "x= torch.randn(5, 2)\n",
        "y = model(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWM8mi-XF5L4",
        "outputId": "058fb8d5-7341-4718-f4d9-6220c598b58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5817, 0.5450, 0.4805],\n",
            "        [0.5773, 0.5439, 0.4822],\n",
            "        [0.5831, 0.5465, 0.4810],\n",
            "        [0.5812, 0.5461, 0.4818],\n",
            "        [0.5806, 0.5458, 0.4818]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "\n",
        "print(model.fc1.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zVjvN71IIeZ",
        "outputId": "eea98f62-80aa-4f20-e33f-70b8fb961e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (fc1): Linear(in_features=2, out_features=5, bias=True)\n",
            "  (fc2): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
            "  (sig1): Sigmoid()\n",
            "  (sig2): Sigmoid()\n",
            "  (sig3): Sigmoid()\n",
            ")\n",
            "Parameter containing:\n",
            "tensor([[ 0.6706,  0.3947],\n",
            "        [ 0.3232,  0.3977],\n",
            "        [ 0.3238, -0.0427],\n",
            "        [ 0.0375,  0.2712],\n",
            "        [ 0.1811, -0.5238]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.sequential = nn.Sequential(\n",
        "        nn.Linear(2,5),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(5,10),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(10,3),\n",
        "        nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.sequential(x)\n",
        "\n",
        "model = MyModel()\n",
        "x= torch.randn(5, 2)\n",
        "y = model(x)\n",
        "print(y)\n",
        "\n",
        "print(model)\n",
        "print(model.sequential[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGlJpJxpITEs",
        "outputId": "0f12ab43-21c1-496d-a871-c4f4fded0f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5319, 0.5622, 0.4027],\n",
            "        [0.5329, 0.5610, 0.4019],\n",
            "        [0.5309, 0.5633, 0.4031],\n",
            "        [0.5326, 0.5608, 0.4033],\n",
            "        [0.5303, 0.5636, 0.4046]], grad_fn=<SigmoidBackward0>)\n",
            "MyModel(\n",
            "  (sequential): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=5, out_features=10, bias=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Linear(in_features=10, out_features=3, bias=True)\n",
            "    (5): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Parameter containing:\n",
            "tensor([[-0.3065,  0.5215],\n",
            "        [-0.5082,  0.2388],\n",
            "        [-0.5340,  0.5179],\n",
            "        [ 0.6009,  0.4899],\n",
            "        [ 0.1358,  0.0663]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = [p.numel() for p in model.parameters() if p.requires_grad] # 학습해야 하는 파라미터들의 엘리먼트 개수\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XB7aoEpIpFr",
        "outputId": "2a6ac32a-b9b8-44df-a172-97c480cb40b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 5, 50, 10, 30, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "weight initialization"
      ],
      "metadata": {
        "id": "gDR_xjWXKpFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1. Linear 레이어 가중치 초기화 (예: nn.Linear(5000, 1000))\n",
        "# ----------------------------------------------------\n",
        "print(\"## 1. Linear Layer Initialization ##\")\n",
        "Fin = 5000  # fan-in: 입력 피처의 수\n",
        "Fout = 1000 # fan-out: 출력 피처의 수\n",
        "\n",
        "# 가중치 텐서 생성 (실제 레이어에서는 (Fout, Fin) 모양)\n",
        "w = torch.empty(Fout, Fin)\n",
        "\n",
        "\n",
        "# (1) mode = 'fan_in': 순전파(Forward Pass)의 안정성을 위함 (가장 일반적)\n",
        "nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\n",
        "# He 초기화의 이론적 표준편차는 sqrt(2 / fan_in)\n",
        "theoretical_std_fan_in = math.sqrt(2 / Fin)\n",
        "\n",
        "print(f\"\\n[Mode: fan_in]\")\n",
        "print(f\"실제 가중치 표준편차: {w.std():.6f}\")\n",
        "print(f\"이론적인 표준편차   : {theoretical_std_fan_in:.6f}\")\n",
        "\n",
        "\n",
        "# (2) mode = 'fan_out': 역전파(Backward Pass)의 안정성을 위함\n",
        "nn.init.kaiming_uniform_(w, mode='fan_out', nonlinearity='relu')\n",
        "# 이론적 표준편차는 sqrt(2 / fan_out)\n",
        "theoretical_std_fan_out = math.sqrt(2 / Fout)\n",
        "\n",
        "print(f\"\\n[Mode: fan_out]\")\n",
        "print(f\"실제 가중치 표준편차: {w.std():.6f}\")\n",
        "print(f\"이론적인 표준편차   : {theoretical_std_fan_out:.6f}\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 2. CNN 레이어 가중치 초기화 (예: nn.Conv2d(64, 128, kernel_size=3))\n",
        "# ----------------------------------------------------\n",
        "print(\"\\n\\n## 2. Convolutional Layer Initialization ##\")\n",
        "C_in = 64      # 입력 채널 수\n",
        "C_out = 128    # 출력 채널 수\n",
        "kH, kW = 3, 3  # 커널(필터)의 높이와 너비\n",
        "\n",
        "# CNN 가중치 텐서 생성 (모양: [출력채널, 입력채널, 커널높이, 커널너비])\n",
        "w_cnn = torch.empty(C_out, C_in, kH, kW)\n",
        "\n",
        "# CNN 에서의 fan_in = C_in * kH * kW\n",
        "cnn_fan_in = C_in * kH * kW\n",
        "theoretical_std_cnn = math.sqrt(2 / cnn_fan_in)\n",
        "\n",
        "# 'fan_in' 모드로 초기화\n",
        "nn.init.kaiming_uniform_(w_cnn, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "print(f\"\\n[Mode: fan_in for CNN]\")\n",
        "print(f\"CNN fan_in 값: {cnn_fan_in}\")\n",
        "print(f\"실제 가중치 표준편차: {w_cnn.std():.6f}\")\n",
        "print(f\"이론적인 표준편차   : {theoretical_std_cnn:.6f}\")"
      ],
      "metadata": {
        "id": "p8cwW2n7Kf40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이진 분류 실습"
      ],
      "metadata": {
        "id": "BaJgu0_-D__-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case 1\n",
        "import torch\n",
        "\n",
        "N = 20\n",
        "random0 = torch.randn(int(N/2), 1)\n",
        "random5 = torch.randn(int(N/2), 1) + 5\n",
        "\n",
        "class1_data = torch.hstack([random0, random5])\n",
        "class2_data = torch.hstack([random5, random0])\n",
        "\n",
        "class1_label = torch.ones(int(N/2), 1)\n",
        "class2_label = torch.zeros(int(N/2), 1)\n",
        "\n",
        "X = torch.vstack([class1_data, class2_data])\n",
        "y = torch.vstack([class1_label, class2_label])"
      ],
      "metadata": {
        "id": "ZUrNRTw-EPCK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(class1_data[:, 0], class1_data[:,1],'o')\n",
        "plt.plot(class2_data[:, 0], class2_data[:,1],'ro')\n",
        "\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('y1')\n",
        "plt.grid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "wvYy8zLrHWOq",
        "outputId": "ef1ffe77-de85-45f3-985e-4468d5fa5401"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP2. 모델 만들기"
      ],
      "metadata": {
        "id": "E9nj6OP7HpVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    #case 1, plain\n",
        "    self.linear = nn.Sequential(nn.Linear(2,100), # 인공신경망은 데이터 1개를 기준. (개X채)\n",
        "                                nn.Sigmoid(),\n",
        "                                nn.Linear(100, 1), # 이진 분류. 1에 가까운지 0에 가까운지만 알면 됨\n",
        "                                nn.Sigmoid())\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n"
      ],
      "metadata": {
        "id": "PDMRycZ1Hg23"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP()\n",
        "print(model)\n",
        "print(model(torch.randn(5,2)).shape) # 5개 데이터에 대한 각각의 출력값. 2개의 값으로 이루어진 좌표값 (x1, x2) 5개 입력한 상태임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WzpzAInH9Dn",
        "outputId": "499cb897-b63e-4bc3-a23d-9c65b4f5c59a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (linear): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=100, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=100, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "  )\n",
            ")\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3. 모델 학습시키기"
      ],
      "metadata": {
        "id": "RieI_mt5I8OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 유닛 스텝으로는 학습이 안되니까, 모든 구간에서 미분가능한 시그모이드를 활성화 함수로 사용\n",
        "# 모든 웨이트에 대해 미분하고, 백워드 (오토그라드)\n",
        "\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "LR = 1e-1\n",
        "EPOCH = 100\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR)\n",
        "\n",
        "loss_history = []\n",
        "\n",
        "model.train() # train mode로 전환\n",
        "for ep in range(EPOCH):\n",
        "  # inference\n",
        "  y_hat = model(X)\n",
        "  # loss\n",
        "  # 이진분류에 쓰이는 비용함수인 BCE는 내부적으로 nn.functional에 구현 되어있음\n",
        "  # 사용자가 해야할 건 모델의 출력과 레이블만 던져주면 된다\n",
        "   # -Sigma (log q^y (1-q)^1-y)\n",
        "   # y_hat이 먼저 파라미터로 들어가야함!!\n",
        "  loss = F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "  # update\n",
        "  loss.backward()\n",
        "  optimizer.step() # 백워드해서 그라디언트 구하고 Optimzer에 step 메서드 해주면, 알아서 그라디언트 가지고 업데이트함\n",
        "\n",
        "  loss_history += [loss.item()]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "609NxtywIqn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "id": "hfy3w-1cKVFA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}